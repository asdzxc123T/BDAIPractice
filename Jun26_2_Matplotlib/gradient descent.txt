최적화 어떻게?
- Gradient Descent(경사하강법)
- ...
- ...
gradient : 편미분한 거 벡터로 쌓은 거
가장 가파른 방향을 향해
값을 가장 크게 증가시키는 방향을 향해
그거 반대방향으로 가면 값을 가장 크게 깎는

learning_rate 없이
x=1에서 g를 구하면 2
1 - 2 = -1
x=-1에서 g를 구하면 -2
-1 - (-2) = 1
x=1에서 g를 구하면 2
1 - 2 = -1
...
-------------------
learning_rate = 0.1로 지정
x = 1에서 g를 구하면 2
1 - 2 * 0.1 = 0.8
x = 0.8에서 g를 구하면 1.6
0.8 - 1.6 * 0.1 = 0.64
...
움직이는 양이 점점 줄어서 0에 가깝게 -> 고임